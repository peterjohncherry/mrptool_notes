\documentclass[12pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{textcomp}
\usepackage{array}
\usepackage{booktabs}
\usepackage[font=small,format=plain,labelfont=bf,up,textfont=it,up]{caption}
\usepackage{longtable}
\usepackage{calc}
\usepackage{setspace}
\usepackage{hhline}
\usepackage{ifthen}
\usepackage{lscape}
\usepackage{pdfpages}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 bottom=20mm,
 right=20mm,
 }
\usepackage{cite}
\linespread{1.3}

\begin{document}
\section{Tensor Operator (TensOp)}
In most cases the ranges of the molecular orbital indexes can be split into a
number of different subranges, which enable us to define each of the operator
tensors as the sum of a number of different blocks, each one associated with a
different combination of these subranges. Decomposing the tensors in this
manner reduces the maximum size of the data structure the computer has to deal
with at any one time. Block decomposition also facilitates the implementation
of symmetry, as many blocks are either equivalent to one another or connected
via some simple transformation. This is particularly relevant in the
relativistic case, where Kramers symmetry can potentially be used to ensure
that the size of the blocks we deal with is no larger than those encountered in
the non-relativistic case.\\

\noindent Before proceeding further it is worth mentioning that the design of
the basic tensor operator object is heavily informed by the functionality
required of the algebraic manipulation routines. For these manipulation 
routines to make sense it is necessary to be very precise about the 
definition of the tensors. Consequently, some of the exposition will 
seem tedious, and the design choices unnatural, at least until the algorithms in the main algebraic
manipulator are discussed.\\ 

\noindent The design of this object is easiest explained by example. Consider an operator; $\hat{Q}$,
which may be written in second quantized form as
\begin{equation}
\hat{Q} =  \sum_{i}^{R^{i}}\sum_{j}^{R^{j}}\sum_{k}^{R^{k}}\sum_{l}^{R^{l}} \hat{a}^{\dagger}_{i} \hat{a}^{\dagger}_{j} \hat{a}_{k} \hat{a}_{l} Q_{ijkl}.
\label{eqn:Q_def}
\end{equation}
\noindent  The coefficients,
$Q_{ijkl}$, can be thought of as elements of a tensor $\mathbf{Q}$, which is
the representation of the operator $\hat{Q}$ in the molecular orbital basis.
I shall refer to such tensors as operator tensors. The $R^{i}$ is just the set
of values over which index $i$ runs (note the range is index specific). This
$R^{i}$ can be broken down into $N_{block}$ disjoint subsets or sub ranges, i.e.,
\begin{equation}
R^{i} = r_{1}^{i} \cup r_{2}^{i} \cup r_{3}^{i} \cup ... = \bigcup^{N_{block}}_{\mu} r_{\mu}^{i}
\end{equation}
\noindent A range block, $\mathbf{B}$, specifies the combinations of indexes which lie within some specified ranges. For example, the (ordered) set
of sub ranges, $\{ r_{\mu},\text{\ } r_{\nu}, \text{\ }r_{\xi}, \text{\ } r_{\chi} \}$, defines range block $B^{\mu\nu\xi\chi}$, which specifies the set
of ranges.
\begin{equation}
B^{\mu\nu\xi\chi} :=  \{ \{i,j,k,l\}  \text{\ }|  \text{\ }i \in \ r_{\mu}^{i} , \text{\ } j \in r_{\nu}^{j},  \text{\ } k \in r_{\xi}^{k},  \text{\ }l\in r^{l}_{\chi} \}.
\end{equation}
The components, $ Q_{ijkl}^{b}$, of a tensor block, $\mathbf{Q}^{b}$ are those blocks which satisfy
\begin{equation}
Q_{ijkl} \in \mathbf{Q}^{b} \text{ \ \ iff \ \ }  \{ i, j, k, l \} \in b   
\end{equation}
using this notation we can rewrite (\ref{eqn:Q_def}) as 
\begin{equation}
\hat{Q} =  \sum_{b}^{\{B\}} \sum_{\{i,j,k,l\}}^{b }
\hat{a}^{\dagger}_{i} \hat{a}^{\dagger}_{j} \hat{a}_{k} \hat{a}_{l} Q_{ijkl}.
\label{eqn:Q_block_def}
\end{equation}
\noindent 

\noindent For each operator $\hat{Q}$, we store a single \emph{TensOp} object, which corresponding to
a molecular orbital tensor $\mathbf{Q}$. This object contains a list of blocks, $Q^{b}$, information about which is stored
in  \emph{CtrTensorPart} objects. To facilitate the exploitation of symmetry and sparsity, the task list generated by the program 
only contains instructions referring to tensor blocks, never the full operators themselves.

\subsection { Block symmetry and sparsity }

Some blocks of the tensor can be obtained by transforming other blocks. How the program exploits this is best explained
through a series of examples.\\ 

\noindent Consider two tensor blocks $Q^{b1}$ and $Q^{b2}$ between which there is the relation
\begin{equation}
Q^{b1}_{ijkl} = Q^{b2}_{ijlk}\rho,
\label{eqn:Qsymm}
\end{equation}
where $b1 = B^{\xi\xi\chi\xi }$, $b2 := B^{\xi\xi\xi\chi }$, and $\rho$ is some constant factor. This is a special case were the ranges $r^{\xi}$ and $r^{\chi}$ have
the same length:
\begin{equation}
\text{card}(r^{\xi}) = \text{card}(r^{\chi}).
\end{equation}
This case regularly occurs when dealing with spin symmetry. Here an element of block $Q^{b1}$ is equal to an element of block $Q^{b2}$ with the last two indexes interchanged.
Therefore, we do not need to store both blocks; operations on $Q^{b2}$ are equivalent to operations on $Q^{b1}$ preceeded by a transformation.\\

\noindent Now consider a third, unrelated tensor block $R^{b3}$, where $b3 := \{\xi, \xi, \chi, \xi, \nu, \nu \}$. 
This tensor block is large, and $r^{\nu}$ has far greater extent than $r^{\chi}$, i.e.,
\begin{equation}
\text{card}(r^{\nu}) \gg \text{card}(r^{\chi})
\end{equation}

\noindent For example, consider calculation of elements of a tensor $\mathbf{X}$ from contractions between tensors $\mathbf{Q}$ and $\mathbf{R}$;
\begin{equation}
X_{mn} = \sum_{ijkl} Q^{b1}_{ijkl} R_{ijklmn}+ \sum_{ijkl} R^{b3}_{ijlkmn}Q^{b2}_{ijkl}.
\label{eqn:Xexample}
\end{equation} 
Note that the $l$ and $k$ indexes on $R$ have been interchanged. \\

\noindent A straight forward way to calculate this is by the following two tasks:
\begin{equation*}
\text{task A1\ : \ \ \  \ } X_{mn} = \sum_{ijkl}  Q^{b1}_{ijkl}R^{b3}_{ijklmn},
\end{equation*}                                                             
\begin{equation*}                                                           
\text{task A2\ : \ \ \  \ } X_{mn} += \sum_{ijkl} Q^{b2}_{ijlk}R^{b3}_{ijklmn}.
\end{equation*}
where the indexes on $Q^{b2}$ have been swapped to avoid the swapping the indexes on $R$.
Applying symmetry we end up with three tasks, but don't need to store $Q^{b2}$, i.e., 
\begin{equation*}
\text{task B1\ : \ \ \  \ } X_{mn} = \sum_{ijkl}  Q^{b1}_{ijkl}R^{b3}_{ijklmn}
\end{equation*}                                                             
\begin{equation*}                                                           
\text{task B2\ : \ \ \  \ } Q^{b2}_{ijkl} = - (\text{swap}(k,l)[ Q^{b1}_{ijkl}])
\end{equation*}
\begin{equation*}                                                           
\text{task B3\ : \ \ \  \ } X_{mn} += \sum_{ijkl} Q^{b2}_{ijkl}R^{b3}_{ijlkmn}
\end{equation*}
However, this saves on storage, not computation time. A better approach would be
\begin{equation*}                                                           
\text{task D1\ : \ \ \  \ } A^{b1}_{ijkl} =  Q^{b1}_{ijkl} + \rho(\text{swap}(k,l)[Q^{b1}_{ijkl}] ) 
\end{equation*}
\begin{equation*}                                                           
\text{task D2\ : \ \ \  \ } X_{mn} = \sum_{ijkl} A^{b1}_{ijkl}R^{b3}_{ijklmn}.
\end{equation*}
This could be improved even further to
\begin{equation*}                                                           
\text{task E1\ : \ \ \  \ } X_{mn} = \sum_{ijkl} (1+\rho) Q^{b1}_{ijkl}R^{b3}_{ijklmn}.
\end{equation*}
\noindent Getting to this final task list, containing just task E1, can be
extremely beneficial, not only because we can often replace several transposes
and summations with a single scalar multiplication, but also because if $\rho =
-1$, then no computation needs to be performed at all.\\  

\noindent To go from tasks $A1$ and $A2$ to tasks $D1$ and $D2$ all that is
required is that whenever the program wants the data for tensor block $Q^{b2}$,
it instead fetches the data for $Q^{b2}$ and performs the appropriate
transformation.\\

\noindent Ensuring that tasks $D1$ and $D2$ are replaced by task
$E1$ is a bit more involved, as it requires that symmetry is accounted 
for during the construction of the task list. The full details of this
will wait until the next section, but it the basic ideas governing 
how symmetry is handled can be discussed now.

\noindent The set of all the blocks of a tensor, $B$, can be generated by applying
the appropriate transformations to some subset of these blocks;
\begin{equation*}
S : \tilde{B} \rightarrow B  \text { \ \ \ } \tilde{B} \subset B
\end{equation*}
\begin{equation*}
   \tilde{b} \mapsto b   \text { \ \ \ } \tilde b\in \tilde{B} \text{ \ \ \ } b \in B
\end{equation*}
\begin{equation}
   b = t \tilde{b} 
\end{equation}
Only the data corresponding to the minimal set, $\tilde{b}$, of blocks is stored. 
Each \emph{TensOp} object contains a list of \emph{rangeblock} objects, which
define this mapping between the original block (in the full set, $B$), and
the unique range block (from the minimal set, $\tilde{B}$). Loosely speaking,
the algebraic manipulation routines just replace all appearances of the original 
blocks with unique blocks, plus some transformation.\\ 

\noindent It is important that the minimal set of blocks is consistent, so
that if the same operator appears at multiple places in the same expression, only
subject to different transformations, no unnecessary blocks are stored. For
example, $\mathbf{\lambda}$, should correspond to the same minimal
set as $\lambda^{T}$. Accordingly, the transformations routines are 
written such that multiple transformations can be applied to the same block; in this case
there is a transpose operation, followed by the transformation into the minimal set 
associated with $\lambda$. Note that actual data  corresponding to the tensor representations
(i.e., the large, many index arrays) is not being transformed, only the algebraic objects 
which represent this data using the task list construction.

\noindent It is important to note that the tensor blocks themselves are 

\subsection{ MultiTensOp } 
\noindent Another important matter is combinations of multiple operators, e.g.,
\begin{equation}
\langle I | \hat{lambda}\hat{H}\hat{T} | J \rangle .
\end{equation}
The symmetry operations associated with these operators are combined; the increase in the saving
associated with block symmetry is multiplicative, and so increases steeply with
the number of concatenated operators. Furthermore, there is a canonical
operator ordering, so as to avoid storing multiple terms which differ only by some transpose, 
e.g., 
\begin{equation}
lambda^{b1}H^{b1}T^{b1} = T^{b1}H^{b1}\lambda^{b1}. 
\label{eqn:tens_block_combined}
\end{equation}
\subsection{CtrTensOp and CtrMultiTensOp}
The task list generator often produces terms which are formed from contractions between indexes either
on the same,
\begin{equation*}
H^{(b1,jk)}_{il} = \sum_{jk} H^{b1}_{ijkl}\delta{jk},
\end{equation*}
or different tensors, 
\begin{equation}
[HT]^{(b1,b2,jz,kw)}_{ilxy} = \sum_{jz} \sum_{kw} H^{b1}_{ijkl}T^{b2}_{wxyz}\delta{jz}\delta{kw}.
\label{eqn:cmtp_example}
\end{equation}
These correspond to the CtrTensOp object; note that once the contraction between $H$ and $T$ has occured, they
are usually inextricable (short of performing some potentially expensive decomposition), and so 
are treated just like a normal tensor block. In terms involving two
tensors which are not contracted all operations on the product tensor should be decomposed into operations of these 
two individual tensors\footnote{this is currently not done everywhere in the code} (note that decomposing the
operation does not, in the cases relevant here, carry the same cost as decomposing the tensors).\\

\noindent It is vital that all transformations are taken account of before the task list of required contractions
is generated. Hence, the RHS in (\ref{eqn:cmpt_example}) above may well be replaced with something like this in
the algebraic task list
\begin{equation}
[HT]^{(b1,b2,jz,kw)}_{ilxy} \mapsto \sum_{ix} \sum_{ly} \rho(H^{\tilde{b1}}_{jilk}T^{\tilde{b2}}_{yzwx}\delta{ix}\delta{ly}).
\label{eqn:cmtp_example_symm}
\end{equation}
\noindent Here the orignal blocks,  $b1$ and $b2$, have been replaced with blocks, $\tilde{b1}$ and $\tilde{b2}$,
from the minimal set, the indexes reshuffled, and a factor $\rho$ associated with the various transformations has appeared. 

\subsection{ Contraction procedure } 
\noindent In most contexts, the tensor contractions are performed using a recursive sequence of binary contractions. For example,
\begin{equation}
A_{kwzm} = 
[BCD]^{(jy,lx,no,pi)}_{kwzm} = \sum_{jy}\sum_{no}\sum_{lx}\sum_{ip} B_{ijkl}C_{mnop}D_{wxyz} \delta_{jy} \delta_{no} \delta_{lx}\delta_{ip}
\end{equation}
Would be obtained  through the following sequence of operations:
\begin{equation*}
\text{Task1 \ : \ \ }
[C]^{(no)}_{mp} = \sum_{no} C_{mnop}\delta_{no}.
\end{equation*}
\begin{equation*}
\text{Task2 \ : \ \ }
[BC]^{(ip,no)}_{jklm} = \sum_{pi} B_{ijkl}[C]_{mp}^{(no)}\delta_{ip}.
\end{equation*}
\begin{equation*}
\text{Task3 \ : \ \ }
[BCD]^{(ip,no,jy)}_{klmwxq} = \sum_{jy} [BC]^{(ip,no)}_{jklm} D_{wxqy}\delta_{jy}.
\end{equation*}
\begin{equation*}
\text{Task4 \ : \ \ }
[BCD]^{(ip,no,jy,lx)}_{kmwq} = \sum_{lx} [BC]^{(ip,no)}_{klmwxq} D_{wxqy}\delta_{lx}.
\end{equation*}
The task list is generated from the information stored in the CtrMultiTensOp corresponding to $[BCD]^{(jy,lx,no,pi)}_{kwzm}$, 
and is done in accordance with the following principles:

\noindent Principle 1 : Contractions between indexes on the same tensor are performed first; this is to keep the rank of the largest tensor to be stored to
a minimum. For example, if the first two tasks were reversed:
\begin{equation*}
\text{Task1' \ : \ \ }
[BC]^{(ip)}_{jklmno} = \sum_{pi} B_{ijkl}[C]_{mp}^{(no)}\delta_{ip}.
\end{equation*}
\begin{equation*}
\text{Task2' \ : \ \ }
[BC]^{(ip,no)}_{jklm} = \sum_{pi} [BC]^{(ip)}_{jklmno}\delta_{no}.
\end{equation*}
the most expensive operation will be contraction of two  4-index tensors, whereas in original formulation, the most expensive is contraction
of a 4-index tensor with a 2-index tensor.\\
The ordering of the contractions is always the same, e.g.,  the task lists for $[BCD]^{(jy,lx,no,pi)}_{kwzm}$ and
$[BCD]^{(kw,lz,no,pi)}_{jxym}$ will always perform the contraction over $(n,o)$ first, followed by the contraction over $(i,p)$. This
means that the $[BC]^{(ip,no)}_{jklm}$ can be reused, and the first two tasks need not be repeated. \\

\noindent Principle 2 : Item Each of these "intermediate" tensors is given a
use number; which increases and decreases as the operations are performed, so
that it can be deleted once it is no longer needed\footnote{The count is
already implemented, but the deletion is not.}.

\noindent Principle 3 : A canonical ordering is defined for the indexes, and
any transpositions are defined relative to this canonical order. e.g., tensor
$B$ always appears to the left of $C$, and index $i$ always appears to the left
of $j$. 

\noindent Principle 4 : Further to the above point, the contraction
task list is performed on using the unique blocks (blocks from $\tilde{B}
\subset B$).  The transformations connecting the unique blocks to the original
blocks have two components, a multiplicative factor \footnote{Or possibly a complex conjugation,
which reduces to a factor when using real arithmetic.}, and an index rearrangement. Rather than
transforming the tensor blocks and then executing the task list, the task list is constructed 
so that the indexes over which the contractions are performed are altered to reflect the necessary transformations,
and only once the contraction list is executed are the necessary transpositions performed. For example, suppose we 
would like to calculate
\begin{equation}
A_{kwzm} = 
[BCD]^{((b1,b2,b3),(jy,lx,mo,kp))}_{inwz} = \sum_{jy}\sum_{no}\sum_{lx}\sum_{ip} B_{ijkl}C_{mnop}D_{wxyz} \delta_{jy} \delta_{no} \delta_{lx}\delta_{ip}
\end{equation}
whilst taking advantage of the following symmetry operations:
\begin{equation*}
B_{ijkl}^{b1} = B_{klij}^{\tilde{b1}}  \text{ \ \ ( 0123 $\rightarrow$ 2301 ) }
\end{equation*}
\begin{equation*}
C_{mnop}^{b2} = C_{nmop}^{\tilde{b2}}  \text{ \ \ ( 0123 $\rightarrow$ 1023 ) }
\end{equation*}
\begin{equation*}
D_{wxyz}^{b3} = D_{zxyw}^{\tilde{b3}}  \text{ \ \ ( 0123 $\rightarrow$ 3120 ) }
\end{equation*}
The following tasks would be performed,
\begin{equation*}
\text{Task1 \ : \ \ }
[C]^{(\tilde{b2}, no)}_{mp} = \sum_{no} C^{\tilde{b2}}_{mnop}\delta_{no}   \text{ \ \ \ $\delta_{mo} \rightarrow \delta_{no}$ }.
\end{equation*}
\begin{equation*}
\text{Task2 \ : \ \ }
[BC]^{((\tilde{b1},tilde_{b2}),(ip,no))}_{jklm} = \sum_{pi} B_{ijkl}[C]_{mp}^{(no)}\delta_{ip} 
\text{ \ \ \ $\delta_{kp} \rightarrow \delta_{ip}$ }.
\end{equation*}
\begin{equation*}
\text{Task3 \ : \ \ }
[BCD]^{(ip,ly,no)}_{klmwxz} = \sum_{ly} [BC]^{(ip,no)}_{jklm} D_{wxyz}\delta_{ly}. 
\text{ \ \ \ $\delta_{lx} \rightarrow \delta_{ly}$ }.
\end{equation*}
\begin{equation*}
\text{Task4 \ : \ \ }
[BCD]^{(ip,ly,mx,no)}_{klwz} = \sum_{mx} [BC]^{(ip,no)}_{klmwxz} D_{wxyz}\delta_{mx}.
\text{ \ \ \ $\delta_{jy} \rightarrow \delta_{mx}$ }.
\end{equation*}
\begin{equation*}
\text{Task5 \ : \ \ }
[BCD]^{((b1,b2,b3),(jy,lx,mo,kp))}_{inwz} = swap(0,1) [BCD]^{(ip,ly,mx,no)}_{klwz}
\end{equation*}
where changes to contractions versus those that would be performed on the untransformed blocks are noted on the right.
Note that by waiting until the last possible moment to apply the symmetry transformations to the blocks,
only one block transposition is required (not quite, fix this), and it becomes possible to reuse the
$[BC]^{((\tilde{b1},tilde_{b2}),(ip,no))}_{jklm}$ obtained from earlier contraction lists.

\noindent Principle 5 : All factors
arising from symmetry transformations are applied after all necessary
contractions have been performed. This keeps the size of the array which needs
to be scaled, and also because different task lists which use the same tensor
may involve different factors.

\end{document}
